---
title: "TalkingData AdTracking Fraud Detection Challenge"
author: "Pablo Aguiar Raposo"
date: "30/04/2022"
output:
  html_document:
    highlight: textmate
    theme: flatly
    number_sections: yes
    toc: yes
    toc_float:
      collapsed: yes
  pdf_document:
    toc: yes
subtitle: Análise de dados + criação de um modelo de machine learningcom redes neurais e random forest para detecção de cliques fraudulentos.
---
# Introdução:  Motivação, objetivo, carregamento dos dados e análise exploratória inicial
OBS: Este projeto é baseado em um competição do Kaggle. Os datasets estão presentes em https://www.kaggle.com/competitions/talkingdata-adtracking-fraud-detection/data. Todo o trabalho foi realizado em linguagem R e o relatório final foi obtido através do Rmarkdown.

## Objetivo
   Analisar os dados disponibilizados pela empres Talkingdata e criar um modelo de machine learning que determinará se um clique é fraudulento ou não, usando redes neurais e random forest.

## Motivação

   O risco de fraude está em toda parte, mas para as empresas que anunciam 
online, a fraude de cliques pode acontecer em um volume avassalador, 
resultando em dados de cliques enganosos e dinheiro desperdiçado. Os canais de 
anúncios podem aumentar os custos simplesmente quando pessoas ou bots 
clicam nos anúncios em grande escala, o que na prática não gera o resultado 
esperado. Com mais de 1 bilhão de dispositivos móveis em uso todos os meses, a 
China é o maior mercado móvel do mundo e, portanto, sofre com grandes 
volumes de tráfego fraudulento.
Neste projeto, utilizaremos um dataset disponibilizado pela empresa Talkingdata, para construir uma análise de dados e um modelo de machine learning que classifica um clique como sendo fraudulento ou não.

## Datasets utilizados: 
train_sample: Amostra do conjunto com os dados históricos fornecidos. Usaremos uma amostra aleatória com 200 mil registros, por limitações de hardware, o que diminuirá a perfomance do modelo preditivo, porém não fará diferença para fins didáticos. 

## Dicionário de dados:
### ip: endereço de IP do clique;
### app: ID do aplicativo usado no marketing;
### device: ID do tipo de aparelho utilizado;
### os: Versão do sistema operacional do aparelho;
### channel: ID do canal do anuciante
### click_time: Horário de clique (UTC)
### attributed_time: Se o usuário fez o download do app, o horário em que foi feito esse download
### is_attributed: Variável a ser prevista, indica se o app foi baixado(1) ou não(0).




## Carregando pacotes utilizados no projeto

``` {r pacote, warning= FALSE, message=FALSE}
library(ggplot2)
library(neuralnet)
library(caret)
library(dplyr)
library(randomForest)
library(data.table)
library(knitr)
```

## Carregando dados

```{r}
data <- fread("train_sample.csv", header = T)
```

## seed

```{r}
set.seed(15)
```

## Visualizando os dados
```{r}
str(data)
```
```{r}
kable(head(data))
```

A coluna 'attributed_time' possui grande quantidade de valores NA, pois ela só está presente quando o download do app é relaizado. 

#### Checando a existência de valores NA para outras variáveis
```{r}
sum(is.na(data[,-'attributed_time']))
```
#### Verificando se existe algum erro com as variáveis temporais, verificando se existe registro de algum download ocorrendo antes do click na propaganda
```{r}
x = data %>% filter(click_time - attributed_time > 0)
nrow(x)
```
Podemos perceber que está tudo correto.

# Data munging

## Checando através de um plot a quantidade de valores únicos de cada uma das variáveis.
```{r}
unique_values <- data[,-c('click_time','attributed_time')]
unique_values <- as.data.frame(apply(unique_values, 2, function(x) length(unique(x))))
unique_values$names <- rownames(unique_values)
colnames(unique_values) <- c('valores_unicos','variavel')
unique_values <- unique_values %>% arrange(desc(valores_unicos))

ggplot(unique_values, aes( x=reorder(variavel,-valores_unicos),valores_unicos)) +
  geom_bar(position='dodge', stat='identity',fill = "blue") + 
  geom_text(aes(label=valores_unicos), position=position_dodge(width=0.9), vjust=-0.25)
```

Podemos perceber uma enorme quantidade de IPs únicos. Importante notar que a variável que iremos prever possui apenas 2 valores únicos, que é o comportamento esperado.

## Balanceamento de variável
Em problemas de classificação, é importante que a variável a ser prevista esteja balanceada, ou seja, a quantidade de valores 0 e de valores 1 em 'is_attributed' deve ser parecida.

##### Vamos plotar essas quantidades
```{r}
ggplot(data, aes(is_attributed)) + geom_bar(fill = 'cornsilk2') +
  stat_count(geom = "text", colour = "black", size = 5,
             aes(label = ..count..),position=position_stack(vjust=0.5))
```
 
 Percebemos uma enorme necessidade de balancear os dados.Podemos fazer isso reduzindo nossa amostra onde 'is_attributed' for 0 ou criando dados em que 'is_attributed' é 1.
 Como temos acesso a uma quantidade muito grande de dados, usaremos uma técnica de downsample
 
```{r}
yes <- which(data$is_attributed == 1)
no <- which(data$is_attributed == 0)
not_downloaded_sample <- sample(no, length(yes))
data = data[c(not_downloaded_sample,yes),]
```

### Verificando
```{r}
ggplot(data, aes(is_attributed)) + geom_bar(fill = 'cornsilk2') +
  stat_count(geom = "text", colour = "black", size = 5,
             aes(label = ..count..),position=position_stack(vjust=0.5))
```

Agora sim a variável target está balanceada.

## Criando coluna com dia da semana e horário do clique
``` {r}
data$dayweek =  wday(data$click_time)
data$hour = hour(data$click_time)
```

``` {r}
kable(head(data[,c('click_time','dayweek','hour')]))
```



#         Análise - quem fez o download do app

## Criando subset apenas com os dados dos que baixaram o app(data2)
``` {r}
data2 = subset(data, data$is_attributed == 1)
```


## Análise: média de tempo levado para download do app
``` {r}
data2$delay = as.numeric(data2$attributed_time - data2$click_time)
```
``` {r}
mean(data2$delay/60)
sd(data2$delay/60)
hist(data2$delay, breaks = 10, col = 'lightblue')
```

### Considerando pessoas que demoraram menos de 10min(600s)
``` {r}
delay_under10 = subset(data2, select = delay, subset = delay<600 )
mean(delay_under10$delay/60)
sd(delay_under10$delay/60)
hist(delay_under10$delay, breaks = 10, col = 'lightblue')
```

### % de pessoas que baixaram o app
``` {r}
a = nrow(data2) 
b = nrow(data)
a/b*100
```

### % de pessoas que baixaram o app em menos de 2 minutos(120s)
``` {r}
c = subset(data2, subset = data2$delay < 120)
d = nrow(c)
d/a*100
```

### Concluímos que, das pessoas que baixaram o app, `r d/a*100 ` o fizeram em menos de 2 minutos, apesar da média ser de `r mean(data2$delay/60) ` minutos. 

## Descobrindo quantos dias estão presentes no nosso dataset
``` {r}
max(data$click_time) - min(data$click_time)
```
         
## Criando um gráfico que mostra o horário do click em uma propaganda, comparando quem fez o download com quem não fez.

``` {r}
data %>%
  group_by(hour) %>%
  summarise(downloadsRealized = sum(is_attributed),
            unrealizedDownloads = sum(!is_attributed)) %>%
  ggplot(x = factor(hour)) +
  geom_line(aes(x = hour, y = downloadsRealized, color = 'Sim')) +
  geom_line(aes(x = hour, y = unrealizedDownloads, color = 'Não')) +
  theme_bw(base_size = 15) + 
  theme(axis.text.x = element_text(angle = 60, hjust = 1)) + 
  xlab('Hora') +
  ylab('Quantidade de cliques') +
  labs(title = 'Análise temporal de cliques', colour = 'Downloaded')
``` 

## Analizando os IPs que fizeram ou não o download.

#### Ips que fizeram o download:
``` {r}
ip_downloaded = data %>% select(c('ip', 'is_attributed')) %>% filter(is_attributed == 1) %>% distinct()
```

#### Ips que não fizeram o dowload
``` {r}
ip_not_donwloaded = data %>% select(c('ip', 'is_attributed')) %>% filter(is_attributed == 0) %>% distinct()
```

#### IPs que pertencem aos dois grupos
``` {r}
ip_both = ip_downloaded %>% inner_join(ip_not_donwloaded , by = 'ip')
count(ip_downloaded)
count(ip_not_donwloaded)
count(ip_both)
```

É possível perceber que uma quantidade extremamente baixa de IPs foi responsável por cliques fraudulentos e cliques não fraudulentos. Assim, percebemos que o mesmo IP costuma ter o mesmo comportamento, seja fraudar o clique ou não.

``` {r}
ip_only_downloaded = ip_downloaded %>% anti_join(ip_both)
ip_only_not_downloaded = ip_not_donwloaded %>% anti_join(ip_both)
total_IP = count(ip_downloaded) + count(ip_not_donwloaded) - count(ip_both)
count(ip_only_downloaded) / total_IP *100
count(ip_only_not_downloaded) / total_IP *100
``` 

O total de Ips que nunca resultaram em cliques fraudulentos é de `r count(ip_only_downloaded) / total_IP *100` % . Já o total que sempre resultou em clique fraudulento é de `r count(ip_only_not_downloaded) / total_IP *100` %





#             Feature selection - Seleção de variáveis que entrarão no


## Eliminando colunas que não entrarão no modelo
``` {r}
data$attributed_time = NULL
data$click_time = NULL
data$ip = NULL
```

## Visualisando o comportamento das variáveis para cada classificação a ser prevista.
### Comparativo: horário de click
``` {r, echo=FALSE, out.width="50%"}
ggplot(data, aes(hour)) +
  geom_bar(fill = 'deepskyblue3') + 
  facet_grid(. ~ is_attributed)
```

### Gráfico: dia da semana
``` {r, echo=FALSE, out.width="50%"}
ggplot(data, aes(dayweek)) +
  geom_bar(fill = 'deepskyblue3') + 
  facet_grid(. ~ is_attributed)
```

### Gráfico: app
``` {r, echo=FALSE, out.width="50%"}
ggplot(data, aes(app)) +
  geom_histogram(fill = 'deepskyblue3') + 
  facet_grid(. ~ is_attributed)
```

### Gráfico: dispositivo
``` {r, echo=FALSE, out.width="50%"}
ggplot(data, aes(device)) +
  geom_histogram(fill = 'deepskyblue3') + 
  facet_grid(. ~ is_attributed)
```

### Gráfico: sistema operacional
``` {r, echo=FALSE, out.width="50%"}
ggplot(data, aes(os)) +
  geom_bar(fill = 'deepskyblue3') + 
  facet_grid(. ~ is_attributed)
```

### Gráfico: canal
``` {r, echo=FALSE, out.width="50%"}
ggplot(data, aes(channel)) +
  geom_bar(fill = 'deepskyblue3') + 
  facet_grid(. ~ is_attributed)
```


## Feature selection com random forest
``` {r}
selection <- randomForest(is_attributed ~.,
                          data       = data, 
                         ntree = 100, nodesize = 10, importance = T)
``` 

``` {r} 
varImpPlot(selection)
``` 

A partir do modelo de random forest e da visualização dos gráficos, determinou-se como variáveis fracas: day_week e hour


## Criação dataset(data_3) sem as variáveis fracas, para testar nos modelos
``` {r}
data_3 = data
data_3$dayweek = NULL
data_3$hour =NULL
```

#   Criação dos modelos de machine learning

## Modelo 1 :Rede Neural(NN)


``` {r}
data_nn <- data

```

### Divisão dados treino e teste
``` {r}
sample <- sample.int(n = nrow(data_nn), size = floor(.7*nrow(data_nn)), replace = F)
train_sample_nn <- data_nn[sample, ]
test_sample_nn  <- data_nn[-sample, ]
```
### Criação do modelo 1
``` {r}
modelo_1 = neuralnet(is_attributed ~., train_sample_nn , hidden = 3)
plot(modelo_1)
```
### Previsões
``` {r}
previsoes <- data.frame(observado = test_sample_nn$is_attributed,
                        previsto = predict(modelo_1, newdata = test_sample_nn))

previsoes$previsto <- ifelse (previsoes$previsto > 0.5, 1, 0)
```

### Confusion matrix - avaliando a performance do modelo
``` {r}
confusionMatrix(table(previsoes$observado, previsoes$previsto))
```


## Modelo 2: rede neural com menos parâmetros

``` {r}
data_nn_2 <- data_3


sample <- sample.int(n = nrow(data_nn_2), size = floor(.7*nrow(data_nn_2)), replace = F)
train_sample_nn_2 <- data_nn_2[sample, ]
test_sample_nn_2  <- data_nn_2[-sample, ]
```

### Criação do modelo 2
``` {r}
modelo_2 = neuralnet(is_attributed ~., train_sample_nn_2 , hidden = 3  )

#previsões
previsoes2 <- data.frame(observado = test_sample_nn_2$is_attributed,
                        previsto = predict(modelo_2, newdata = test_sample_nn_2))

previsoes2$previsto <- ifelse (previsoes2$previsto > 0.5, 1, 0)
``` 

### Confusion matrix
``` {r}
confusionMatrix(table(previsoes2$observado, previsoes2$previsto))
```

##  Modelo 3 - random forest

``` {r}
sample <- sample.int(n = nrow(data), size = floor(.7*nrow(data)), replace = F)
train_sample <- data[sample, ]
test_sample  <- data[-sample, ]

modelo_3 <- randomForest(is_attributed ~.,
                          data       = train_sample, 
                          ntree = 100, nodesize = 10)


previsoes3 <- data.frame(observado = test_sample$is_attributed,
                         previsto = predict(modelo_3, newdata = test_sample))

previsoes3$previsto <- ifelse (previsoes3$previsto > 0.5, 1, 0)
```

### Confusion matrix
``` {r}
confusionMatrix(table(previsoes3$observado, previsoes3$previsto))
```

## Modelo 4: random forest com menos parâmetros
``` {r}
sample <- sample.int(n = nrow(data_3), size = floor(.7*nrow(data_3)), replace = F)
train_sample <- data_3[sample, ]
test_sample  <- data_3[-sample, ]

modelo_4 <- randomForest(is_attributed ~.,
                         data       = train_sample, 
                         ntree = 100, nodesize = 15)


previsoes4 <- data.frame(observado = test_sample$is_attributed,
                         previsto = predict(modelo_4, newdata = test_sample))

previsoes4$previsto <- ifelse (previsoes4$previsto > 0.5, 1, 0)

```

### Confusion matrix
``` {r}
confusionMatrix(table(previsoes4$observado, previsoes4$previsto))
```


####  Os modelos de random forest apresentaram desempenho superior aos de redes neurais, ultrapassando 90% de acurácia. 

# Dúvidas, sugestões e críticas: entre em contato!   :)
e-mail: pabloaguiar92@hotmail.com   
linkedin: https://www.linkedin.com/in/pablo-aguiar-raposo-71b6b5139/
github: https://github.com/Pablo-aguiarr



